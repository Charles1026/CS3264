{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":85366,"databundleVersionId":9634322,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# CS3264 Assigment 2\nThis is my implementation for assignment 2, my approach is to use ResNet to extract the features from the dataset's training images, then train a one vs all logisitic classifier for each class. Github code can be seen [here](https://github.com/Charles1026/CS3264)","metadata":{}},{"cell_type":"markdown","source":"## Setup Code","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport os\nfrom tqdm import tqdm\nfrom typing import List, Tuple\n\nimport torch\nimport torch.nn as nn\nimport torchvision.io as io\nfrom torchvision.models.resnet import resnet18, ResNet18_Weights, ResNet\nimport torchvision.transforms as tx\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\n\nCLASS_NAME_TO_ID_MAP = {\n  \"002_master_chef_can\": 0,\n  \"003_cracker_box\": 1,\n  \"004_sugar_box\": 2,\n  \"005_tomato_soup_can\": 3,\n  \"006_mustard_bottle\": 4,\n  \"007_tuna_fish_can\": 5,\n  \"008_pudding_box\": 6,\n  \"009_gelatin_box\": 7,\n  \"010_potted_meat_can\": 8,\n  \"011_banana\": 9,\n  \"019_pitcher_base\": 10,\n  \"021_bleach_cleanser\": 11,\n  \"024_bowl\": 12,\n  \"025_mug\": 13,\n  \"035_power_drill\": 14,\n  \"036_wood_block\": 15,\n  \"037_scissors\": 16,\n  \"040_large_marker\": 17,\n  \"051_large_clamp\": 18,\n  \"052_extra_large_clamp\": 19,\n  \"061_foam_brick\": 20\n}\n\nINPUT_DIR = \"/kaggle/input/cs3264-assignment-2-ay2425s1\"\nTRAIN_DATSET_DIR = os.path.join(INPUT_DIR, \"ycb_dataset\", \"train_data\")\nTEST_DATSET_DIR = os.path.join(INPUT_DIR, \"ycb_dataset\", \"test_data\")\nFEATURES_OUTPUT_FILE = os.path.join(INPUT_DIR, \"features\", \"combined_features.npz\")\nTRAIN_DATA_FILE = os.path.join(INPUT_DIR, \"features\", \"train_features.npz\")\nTEST_DATA_FILE = os.path.join(INPUT_DIR, \"features\", \"test_features.npz\")\nMODEL_WEIGHTS_FILE = os.path.join(INPUT_DIR, \"features\", \"model_weights.npz\")\nTEST_OUTPUT_FILE = os.path.join(\"/kaggle/working/submission.csv\")\n\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nRESNET_MEAN = torch.tensor([0.485, 0.456, 0.406])\nRESNET_STD = torch.tensor([0.229, 0.224, 0.225])\nRESNET_RESIZER = tx.Resize((224, 224))\n\ndef createResNetNoFCLayer():\n  resnet = resnet18(weights = ResNet18_Weights.DEFAULT)\n  resnet.fc = nn.Identity()\n\n  resnet = resnet.to(DEVICE)\n  return resnet.eval()\n\nclass MultiLabelPredictor(nn.Module):\n  def __init__(self) -> None:\n    super().__init__()\n    self.fc = nn.Linear(512, len(CLASS_NAME_TO_ID_MAP), bias=True)\n    self.sigmoid = torch.nn.Sigmoid()\n    \n  def __init__(self, intercepts: torch.Tensor, coefs: torch.Tensor) -> None:\n    super().__init__()\n    self.fc = nn.Linear(512, len(CLASS_NAME_TO_ID_MAP), bias=True)\n    self.sigmoid = torch.nn.Sigmoid()\n    self.fc.bias.data = intercepts\n    self.fc.weight.data = coefs\n    \n  def forward(self, x):\n    x = self.fc(x)\n    return self.sigmoid(x)\n\ndef createResNetCustomFCLayer(intercepts: torch.Tensor, coefs: torch.Tensor):\n  predictor = MultiLabelPredictor(intercepts, coefs)\n  \n  resnet = resnet18(weights = ResNet18_Weights.DEFAULT)\n  resnet.fc = predictor\n\n  resnet = resnet.to(DEVICE)\n  return resnet.eval()\n\n#TODO: Test if resize helps with feature extraction \ndef prepImageforResnet(img: torch.Tensor):\n  img = img.float() / 255\n  img = (img - RESNET_MEAN[:, None, None]) / RESNET_STD[:, None, None]\n  img= img.unsqueeze(0)\n  return img.to(DEVICE)\n  ","metadata":{"execution":{"iopub.status.busy":"2024-10-16T07:42:24.376806Z","iopub.execute_input":"2024-10-16T07:42:24.377081Z","iopub.status.idle":"2024-10-16T07:42:30.958631Z","shell.execute_reply.started":"2024-10-16T07:42:24.377048Z","shell.execute_reply":"2024-10-16T07:42:30.957726Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Feature Extraction Code","metadata":{}},{"cell_type":"code","source":"@torch.no_grad\ndef loadAndExtractFeaturesAndLabels(resnet:ResNet, rootDir: str, loadLabels: bool = False):\n  featuresList: List = []\n  labelsList: List = []\n\n  for root, subdirs, files in tqdm(os.walk(rootDir), desc = \"Extracing Features\"):\n    for file in files:\n      fileName, fileExt = os.path.splitext(file)\n      if (fileExt != \".png\"): continue\n      \n      img = io.read_image(os.path.join(root, file), io.ImageReadMode.RGB)\n      img = prepImageforResnet(img)\n      imgFeatures = resnet(img)\n      \n      featuresList.append(imgFeatures)\n      \n      if loadLabels:\n        fileNum = fileName.split(\"-\")[0]\n        with open(os.path.join(root, f\"{fileNum}-box.txt\"), \"r\") as labelFile:\n          imgLabels = torch.zeros(len(CLASS_NAME_TO_ID_MAP))\n          for line in labelFile:\n            objName, *boundingBox = line.split()\n            imgLabels[CLASS_NAME_TO_ID_MAP[objName]] = 1\n            \n          labelsList.append(imgLabels.unsqueeze(0))\n          \n  if loadLabels:\n    return torch.cat(featuresList).cpu().numpy(), torch.cat(labelsList).numpy()\n  else:\n    return torch.cat(featuresList).cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2024-10-16T07:42:30.960183Z","iopub.execute_input":"2024-10-16T07:42:30.960593Z","iopub.status.idle":"2024-10-16T07:42:30.970349Z","shell.execute_reply.started":"2024-10-16T07:42:30.960561Z","shell.execute_reply":"2024-10-16T07:42:30.969492Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Split Data","metadata":{}},{"cell_type":"code","source":"def splitData(features: np.ndarray, labels: np.ndarray, trainRatio: float = 0.8) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n  return train_test_split(features, labels, train_size = trainRatio)","metadata":{"execution":{"iopub.status.busy":"2024-10-16T07:42:30.971618Z","iopub.execute_input":"2024-10-16T07:42:30.971934Z","iopub.status.idle":"2024-10-16T07:42:30.981801Z","shell.execute_reply.started":"2024-10-16T07:42:30.971903Z","shell.execute_reply":"2024-10-16T07:42:30.980931Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Train Model","metadata":{}},{"cell_type":"code","source":"def trainModel(features: np.ndarray, labels: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n  interceptList: List = []\n  coefList: List = []\n  for classLabels in tqdm(labels.transpose(), desc=\"Training Models\"):\n    model = LogisticRegression(solver=\"liblinear\")\n    model.fit(features, classLabels)\n    interceptList.append(model.intercept_)\n    coefList.append(model.coef_)\n    \n  return np.stack(interceptList), np.stack(coefList)","metadata":{"execution":{"iopub.status.busy":"2024-10-16T07:42:30.983639Z","iopub.execute_input":"2024-10-16T07:42:30.983928Z","iopub.status.idle":"2024-10-16T07:42:30.996163Z","shell.execute_reply.started":"2024-10-16T07:42:30.983897Z","shell.execute_reply":"2024-10-16T07:42:30.995291Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Validate Model","metadata":{}},{"cell_type":"code","source":"def validateModel(model: MultiLabelPredictor, features: torch.Tensor, labels: torch.Tensor):\n  predY = model(features.to(DEVICE)).cpu()\n  predLabels = torch.round(predY)\n  \n  print(f\"{torch.sum(torch.abs(labels - predLabels)).int()} / {labels.shape[0] * labels.shape[1]} incorrect matches\")\n  \n  totalF1Score = 0\n  for labelIdx in range(labels.shape[1]):\n    tn = 0.0\n    fn = 0.0\n    fp = 0.0\n    tp = 0.0\n    for sampleIdx in range(labels.shape[0]):\n      if (predLabels[sampleIdx][labelIdx] == 0) and (labels[sampleIdx][labelIdx] == 0):\n        tn += 1\n        \n      elif (predLabels[sampleIdx][labelIdx] == 0) and (labels[sampleIdx][labelIdx] == 1):\n        fn += 1\n        \n      elif (predLabels[sampleIdx][labelIdx] == 1) and (labels[sampleIdx][labelIdx] == 0):\n        fp += 1\n        \n      elif (predLabels[sampleIdx][labelIdx] == 1) and (labels[sampleIdx][labelIdx] == 1):\n        tp += 1\n        \n    precision = tp / (tp + fp)\n    recall = tp / (tp + fn)\n    f1 = 2 * ((precision * recall) / (precision + recall))\n    totalF1Score += f1\n    \n  return totalF1Score / labels.shape[1]","metadata":{"execution":{"iopub.status.busy":"2024-10-16T07:42:30.997207Z","iopub.execute_input":"2024-10-16T07:42:30.997549Z","iopub.status.idle":"2024-10-16T07:42:31.007144Z","shell.execute_reply.started":"2024-10-16T07:42:30.997507Z","shell.execute_reply":"2024-10-16T07:42:31.006310Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Predict","metadata":{}},{"cell_type":"code","source":"@torch.no_grad\ndef predict(predDir: str, model: ResNet):\n  \n  predList: List = [] \n  for videoId in tqdm(os.listdir(predDir), desc = \"Predicting\"):    \n    videoDir = os.path.join(predDir, videoId)\n    if not os.path.isdir(videoDir): continue\n    \n    for imgId in os.listdir(videoDir):\n      imgFile = os.path.join(videoDir, imgId)\n      \n      img = io.read_image(imgFile, io.ImageReadMode.RGB)\n      img = prepImageforResnet(img)\n      yPred = model(img)\n      predLabels = torch.round(yPred).int()\n      \n      imgName = imgId.split(\"-\")[0]\n      predList.append((f\"{videoId}_{imgName}\", predLabels.squeeze().cpu().numpy()))\n\n  return predList\n\ndef savePredictions(outFile: str, predictions: List[Tuple[str, np.ndarray]]):\n  with open(outFile, \"w\") as file:\n    file.write(\"img_id,class_0,class_1,class_2,class_3,class_4,class_5,class_6,class_7,class_8,class_9,class_10,class_11,class_12,class_13,class_14,class_15,class_16,class_17,class_18,class_19,class_20\\n\")\n    \n    for name, labels in predictions:\n      file.write(f\"{name},\")\n      for idx, label in enumerate(labels):\n        file.write(str(label))\n        if (idx < labels.shape[0] - 1):\n          file.write(\",\")\n      file.write(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-10-16T07:42:31.008172Z","iopub.execute_input":"2024-10-16T07:42:31.009300Z","iopub.status.idle":"2024-10-16T07:42:31.018988Z","shell.execute_reply.started":"2024-10-16T07:42:31.009252Z","shell.execute_reply":"2024-10-16T07:42:31.018013Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Run Workflow","metadata":{}},{"cell_type":"code","source":"# Feature Extraction\nprint(\"Loading ResNet\")\nresNetNoFC = createResNetNoFCLayer()\n\nfeatures, labels = loadAndExtractFeaturesAndLabels(resNetNoFC, TRAIN_DATSET_DIR, loadLabels = True)\nprint(f\"Extracted the features and labels for {features.shape[0]} images\")\n\n# Split Data\nprint(\"Splitting Data\")\nX_train, X_test, y_train, y_test = splitData(features, labels, 0.9)\n\n# Train Model\nintercepts, coefs = trainModel(X_train, y_train)\n\n# Validate Model\nlogClassifier = MultiLabelPredictor(torch.tensor(intercepts, dtype = torch.float32).squeeze(), torch.tensor(coefs, dtype = torch.float32).squeeze()).to(DEVICE)\nmacroF1Metric = validateModel(logClassifier, torch.tensor(X_test), torch.tensor(y_test))\nprint(f\"Model has macro F1 metric of {macroF1Metric} on validation data.\")\n\n# \nresnet = createResNetCustomFCLayer(torch.tensor(intercepts, dtype = torch.float32).squeeze(), torch.tensor(coefs, dtype = torch.float32).squeeze())\npredictions = predict(TEST_DATSET_DIR, resnet)\nsavePredictions(TEST_OUTPUT_FILE, predictions)","metadata":{"execution":{"iopub.status.busy":"2024-10-16T07:42:31.020128Z","iopub.execute_input":"2024-10-16T07:42:31.020447Z","iopub.status.idle":"2024-10-16T07:44:05.936633Z","shell.execute_reply.started":"2024-10-16T07:42:31.020415Z","shell.execute_reply":"2024-10-16T07:44:05.935642Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Loading ResNet\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 193MB/s]\nExtracing Features: 53it [01:11,  1.36s/it]\n","output_type":"stream"},{"name":"stdout","text":"Extracted the features and labels for 2000 images\nSplitting Data\n","output_type":"stream"},{"name":"stderr","text":"Training Models: 100%|██████████| 21/21 [00:07<00:00,  2.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"35 / 4200 incorrect matches\nModel has macro F1 metric of 0.9808469678302297 on validation data.\n","output_type":"stream"},{"name":"stderr","text":"Predicting: 100%|██████████| 14/14 [00:14<00:00,  1.04s/it]\n","output_type":"stream"}]}]}